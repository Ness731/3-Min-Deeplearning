{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter.7_순차적인_데이터를_처리하는_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpyXbwfD4NK9Ns/GL6sNLN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ness731/3-Min-Deeplearning/blob/main/Chapter.7_%EC%88%9C%EC%B0%A8%EC%A0%81%EC%9D%B8_%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%A5%BC_%EC%B2%98%EB%A6%AC%ED%95%98%EB%8A%94_RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## __RNN(Recurrent Neural Network)__\n",
        "앞서 배운 ANN, DNN, CNN, 오토인코더는 시간에 대한 개념이 없었다. 그러나 우리가 현실에서 접하는 거의 모든 데이터는 순차적(Sequential)이다. 이러한 __순차적인 데이터(시계열 데이터)__를 처리하기 위해서 고안된 신경망이 바로 RNN이다.\n",
        "\n",
        "__| RNN :__ 정해지지 않은 길이의 데이터 배열을 순차적으로 읽고 작업을 수행하는 신경망 <br>\n",
        "\n",
        "__| 특징__<br> \n",
        "- RNN은 __은닉벡터(hidden vector)__를 출력하며, 순차적 데이터의 흐름을 모두 내포한다.\n",
        "- RNN은 어떤 시점에서의 입력값에 대한 출력값을 계산할 때, 직전 출력값을 특정 비율만큼 반영하여 연산한다. (시간개념)\n",
        "<br>\n",
        "\n",
        "__| RNN의 형태__\n",
        "- __일대일__ : 한 개의 입력값에 대응하는 한 개의 출력값을 생성한다.<br>\n",
        "  예) 일반적으로 보아온 신경망\n",
        "- __일대다__ : 한 개의 입력값에 대해 은닉 벡터들을 통과하면서 여러 개의 출력값을 생성한다.<br>\n",
        "  예) 이미지를 보고 안의 상황을 글로 설명하는 문제\n",
        "- __다대일__ : 여러 개의 입력값에 대해 은닉 벡터들을 통과하면서 한 개의 출력값을 생성한다.<br>\n",
        "  예) 챗봇과 기계 번역 같이 순차적인 데이터를 출력하는 문제\n",
        "- __다대다__ : 여러 은닉 벡터를 통해 입력받은 값들에 대해 여러 개의 출력값을 생성한다.<br>\n",
        "  예) 비디오 분류 같이 매 프레임을 레이블링하는 문제<br>\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "URmtx32feSFe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## :: 예제 - 영화 리뷰 감정 분석 ::\n",
        "텍스트 형태의 데이터셋인 IMDB는 영화 리뷰(영어) 5만 건으로 이루어져있으며, 긍정적인 영화 리뷰는 2로, 부정적인 영화 리뷰는 1로 레이블링 되어있다. 이를 사용하여 영화 리뷰의 긍정/부정 여부를 판별하는 모델을 작성한다."
      ],
      "metadata": {
        "id": "BRc5NjpZiOkz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __| 이슈 : 자연어 텍스트를 어떻게 학습하는가?__\n",
        "자연어 텍스트를 인공 신경망에 입력시키기 위해선 __전처리 과정__을 거쳐 __데이터를 숫자로__ 나타내야 하며, 이를 __워드 임베딩(word embedding)__이라고 한다.<br>\n",
        "\n",
        "__[워드 임베딩 과정]__\n",
        "1. __토크나이징(tokenizing)__ : 문장들을 토큰(token)으로 나눈다.\n",
        "2. 모든 토큰을 각각의 __벡터__로 나타낸다.\n",
        "3. 모든 단어 수만큼의 벡터를 담는 __딕셔너리(dictionary)__를 정의한다.\n"
      ],
      "metadata": {
        "id": "Cg7wpq5DoFE9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torchtext==0.10.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XDeKnpNbuVLB",
        "outputId": "830590d5-79c8-43b5-f9a6-98fe179a98ca"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchtext==0.10.0\n",
            "  Downloading torchtext-0.10.0-cp37-cp37m-manylinux1_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 24.7 MB/s \n",
            "\u001b[?25hCollecting torch==1.9.0\n",
            "  Downloading torch-1.9.0-cp37-cp37m-manylinux1_x86_64.whl (831.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 831.4 MB 2.6 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (4.64.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchtext==0.10.0) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0->torchtext==0.10.0) (4.1.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.10.0) (2.10)\n",
            "Installing collected packages: torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.8.0\n",
            "    Uninstalling torchtext-0.8.0:\n",
            "      Successfully uninstalled torchtext-0.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.13.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.9.0 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.9.0 torchtext-0.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "QnFADB6VdAtu"
      },
      "outputs": [],
      "source": [
        "# 라이브러리 import\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchtext.legacy import data, datasets # 라이브러리 에러로 인해 구버전의 torchtext.legacy 사용"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 하이퍼파라미터 정의\n",
        "BATCH_SIZE = 64 # 한 번의 EPOCH에서 다룰 데이터의 양\n",
        "EPOCHS = 40     # 이터레이션 횟수\n",
        "lr = 0.001\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")"
      ],
      "metadata": {
        "id": "u0Mf0kN5qWKN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### __워드 임베딩하기__"
      ],
      "metadata": {
        "id": "BAgMfBZbrkiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 토치텍스트를 이용하여 임베딩 설정 정보를 담은 객체를 생성한다.\n",
        "# sequential: 순차 데이터 여부, lower: 소문자 처리 옵션\n",
        "TEXT = data.Field(sequential=True, batch_first=True, lower=True)\n",
        "LABEL = data.Field(sequential=False, batch_first=True)"
      ],
      "metadata": {
        "id": "I4TPzlG4qywK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. 토크나이징을 통해 모델에 입력되는 학습, 테스트 데이터셋을 만들어준다.\n",
        "trainset, testset=  datasets.IMDB.splits(TEXT, LABEL)"
      ],
      "metadata": {
        "id": "8x1fq0oUsWQZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ef0ebd0-1232-451f-bbf1-457bf4f77b4e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading aclImdb_v1.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "aclImdb_v1.tar.gz: 100%|██████████| 84.1M/84.1M [00:08<00:00, 9.51MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 토큰을 담는 딕셔너리를 생성한다.\n",
        "TEXT.build_vocab(trainset, min_freq=5)\n",
        "LABEL.build_vocab(trainset)"
      ],
      "metadata": {
        "id": "Y_b-933ewYut"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 검증 데이터셋을 추가한다.\n",
        "trainset, valset = trainset.split(split_ratio=0.8) # 2:8의 비율로 분할한다.\n",
        "train_iter, val_iter, test_iter = data.BucketIterator.splits((trainset, valset, testset), batch_size=BATCH_SIZE, shuffle=True, repeat=False)"
      ],
      "metadata": {
        "id": "S_UCesT6yKWl"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(TEXT.vocab) # 딕셔너리 사이즈 (모든 토큰 개수)\n",
        "n_classes = 2 # 레이블 개수 (긍정/부정)"
      ],
      "metadata": {
        "id": "QzYtcMwqyydh"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"[학습 데이터셋]: %d, [검증 데이터셋]: %d, [테스트 데이터셋]: %d, [단어 수]: %d, [레이블 수]: %d\" % (len(trainset), len(valset), len(testset), vocab_size, n_classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bV41UkQcy8Ja",
        "outputId": "bbf67e71-d7c1-45da-9464-6343dc8b8d5e"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[학습 데이터셋]: 20000, [검증 데이터셋]: 5000, [테스트 데이터셋]: 25000, [단어 수]: 46159, [레이블 수]: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###__RNN 모델 구현하기__\n",
        "본 순환신경망 모델에서는 RNN 대신에 GRU를 사용한다. RNN을 사용하면 문장의 뒷부분에 다다를수록 앞부분의 정보가 소실되는 __장기의존성 문제__가 발생하기 때문이다.<br>\n",
        "\n",
        "__| 장기의존성 문제__ <br>\n",
        "RNN에서 입력이 길어지면 학습 도중 기울기가 너무 작아지거나(경사도 소실) 커져서(경사도 폭발) 앞부분에 대한 정보를 정확히 담지 못하는 현상.<br>\n",
        "\n",
        "-> GRU에서는 이러한 문제를 해결하기 위해 순차적 데이터 사이의 정보 전달량을 조절함으로써 기울기를 적정하게 유지하고 문장 앞부분의 정보가 끝까지 도달할 수 있도록 한다."
      ],
      "metadata": {
        "id": "h1-7ar_TzpFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicGRU(nn.Module):\n",
        "  def __init__(self, n_layers, hidden_dim, n_vocab, embed_dim, n_classes, dropout_p=0.2):\n",
        "    super(BasicGRU, self).__init__()\n",
        "    print(\"Building Basic GRU model...\")\n",
        "    \n",
        "    # ***순환신경망 정의를 위해 필요한 파라미터***\n",
        "    self.dropout = nn.Dropout(dropout_p)\n",
        "    # 은닉벡터들의 층\n",
        "    self.n_layers = n_layers\n",
        "    # 은닉벡터의 차원값\n",
        "    self.hidden_dim = hidden_dim\n",
        "    # 임베딩할 단어들의 총 개수, 임베딩된 단어 텐서가 지니는 차원값을 입력받아 임베딩하는 함수\n",
        "    self.embed = nn.Embedding(n_vocab, embed_dim)\n",
        "\n",
        "    # ***순환신경망으로 GRU를 사용***\n",
        "    self.gru = nn.GRU(embed_dim, hidden_dim, num_layers=self.n_layers, batch_first=True)\n",
        "\n",
        "    # 분류층(fc레이어)\n",
        "    self.out = nn.Linear(self.hidden_dim, n_classes)\n",
        "\n",
        "\n",
        "  def forward(self, x): # x: 입력데이터\n",
        "    x = self.embed(x) # 입력 데이터는 자연어 텍스트이므로 임베딩한다.\n",
        "    h_0 = self._init_state(batch_size=x.size(0)) # 첫 번째 은닉벡터는 이전 은닉벡터(t-1)가 없으므로, 별도의 정의가 필요하다.\n",
        "\n",
        "\n",
        "  def _init_state(self, batch_size=1): # 첫 번째 은닉벡터를 정의하는 함수\n",
        "    weight = next(self.parameters()).data\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dun).zero_()"
      ],
      "metadata": {
        "id": "4j0C4n4nziFU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}